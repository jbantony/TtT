{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Deep Learning Intro",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2Lqc3q3DaWy"
      },
      "source": [
        "# Train-the-Trainer Hands-on Workshop: Deep Learning Intro\n",
        "Benjamin Bergner, Stefan Konigorski, Matthias Kirchler (Hasso Plattner Institut)\n",
        "20. November 2020\n",
        "\n",
        "Willkommen zum zweiten Part des Algorithmen Workshops."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69U5uzuEDxjn"
      },
      "source": [
        "## Agenda\n",
        "\n",
        "<a name=\"Agenda\"></a>\n",
        "\n",
        "| Inhalt | Zeit |\n",
        "| :--- | :---: |\n",
        "| Einführung | 10:00 - 10:15 |\n",
        "| 1) Einführung in Machine Learning mit scikit-learn | 10:15 - 11:00|\n",
        "|  a) Klassische Vorhersagemodelle | |\n",
        "|  b) Unüberwachtes Lernen mit Clusteranalyse & PCA | |\n",
        "| Übungen in scikit-learn in Kleingruppen | 11:00 - 11:30|\n",
        "| Besprechung der Ergebnisse | 11:30 - 11:45|\n",
        "| Pause | 11:45 - 12:15|\n",
        "| 2) Einführung in Deep Learning mit fast.ai | 12:15 - 13:00|\n",
        "| Projektarbeit in fast.ai - Kleingruppen | 13:00 - 13:30|\n",
        "| Besprechung der Ergebnisse | 13:30 - 13:45|\n",
        "| Abschluss | 13:45 - 14:00|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrot5c_MKLK2"
      },
      "source": [
        "## Vorbemerkung\n",
        "Bevor Sie mit der Ausführung beginnen, sollten Sie den Laufzeittyp (\"runtime type\", falls Ihre Sprache auf Englisch eingestellt ist) auf \"GPU\" ändern: \n",
        "\n",
        "1.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1uTzSVK4BCAUwxJ1a1b-mB86jwZ_cbFAR\" width=\"400\"/>\n",
        "\n",
        "\n",
        "2.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=11dDC7mx-MyoNIx0jyTiiT4RLtEPmi-aO\" width=\"400\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUwisBfcNice"
      },
      "source": [
        "Als nächstes müssen Sie die folgende Zeile ausführen um benötigte Software zu installieren.\n",
        "\n",
        "Die Fehlermeldung `ERROR: fastai 2.0.6 has requirement fastcore>=1.0.0, but you'll have fastcore 0.1.38 which is incompatible.` können Sie ignorieren. Sollten andere Fehler auftreten, wenden Sie sich bitte an einen der Moderatoren."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvNHLNV2B7x6",
        "cellView": "both"
      },
      "source": [
        "# Diese Zeile muss am Anfang ein mal ausgeführt werden. Danach müssen Sie sie nicht mehr ausführen\n",
        "! pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "! pip install fastai==2.0.6\n",
        "! pip install fastcore==0.1.38"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXPegM_LFSk-"
      },
      "source": [
        "## fast.ai\n",
        "<img style=\"float: left;\" src=\"https://www.fast.ai/images/Fast.ai.png\" width=250>\n",
        "Für Deep Learning benötigen wir eine andere Softwarebibliothek als für klassisches Machine Learning. In fast.ai sind viele Deep Learning Algorithmen vorimplementiert und die meisten Standardoperationen sind automatisiert, so dass mithilfe von wenigen Zeilen Code, ein komplettes tiefes neuronales Netzwerk trainiert werden kann. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iikCeQtcZgch",
        "cellView": "both"
      },
      "source": [
        "# Wir binden fast.ai und eine Helferfunktion so ein:\n",
        "from os import path as osp\n",
        "from fastai.vision.all import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qUlMS_FHujj"
      },
      "source": [
        "# Ein erstes tiefes neuronales Netzwerk\n",
        "<hr>\n",
        "\n",
        "## Ziel\n",
        "\n",
        "Wir lernen die Grundlagen, wie man Bilder in fast.ai einliest und damit ein erstes neuronales Netzwerk trainiert.\n",
        "<hr>\n",
        "\n",
        "## Methoden\n",
        "\n",
        "* Klassifikation von Bilddaten\n",
        "* Convolutional Neural Networks\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKeGj2QPIpHR"
      },
      "source": [
        "## Vorbereitung: Laden von Bilddaten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kHSGXX6I3mz"
      },
      "source": [
        "In der nächsten Zelle wird ein Datensatz von verschiedenen Hunderassen automatisch heruntergeladen. Die Details sind an dieser Stelle nicht wichtig."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBj9AXWraVGO"
      },
      "source": [
        "path_to_data = 'data/imagewoof2-160'\n",
        "if not osp.isdir(path_to_data):\n",
        "  os.makedirs(path_to_data, exist_ok=True)\n",
        "  ! wget https://www.dropbox.com/s/83f1a0lz3fwlytw/imagewoof2-160.tar -O data/imagewoof2-160.tar\n",
        "  ! tar -xf data/imagewoof2-160.tar -C data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8_nMscOJJ7F"
      },
      "source": [
        "Als nächstes laden wir diesen Datensatz in einen `ImageDataLoader`, also einen Helfer, der für uns die Bilder automatisch lädt:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_KrDeFeZgcl"
      },
      "source": [
        "size = 128\n",
        "data = ImageDataLoaders.from_folder(\n",
        "    path_to_data,\n",
        "    train='train',\n",
        "    valid='val',\n",
        "    item_tfms=[Resize(size)],\n",
        ")\n",
        "data.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8jprR3vJtby"
      },
      "source": [
        "## Der erste Trainingsversuch\n",
        "\n",
        "Und jetzt können wir schon ein neuronales Netzwerk trainieren! Wir verwenden den Befehl `cnn_learner` um automatisch ein Convolutional Neural Network vorbereitet zu bekommen. An dieser Stelle verwenden wir ein sogenanntes \"ResNet\" der Tiefe 18."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buETDPcJZgco"
      },
      "source": [
        "learner = cnn_learner(data, resnet18, metrics=error_rate, pretrained=False)\n",
        "# der Befehl `fit` sagt dem Netzwerk, dass es trainieren soll\n",
        "learner.fit(6, lr=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFguET2yZgcr"
      },
      "source": [
        "# zeige an, wie sich das CNN geschlagen hat\n",
        "learner.recorder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWxiefJbZgcu"
      },
      "source": [
        "**Was für eine Enttäuschung!** -- was haben wir falsch gemacht?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLUGhU6LZgcx"
      },
      "source": [
        "# Verbesserung 1: - Die Lernrate // Learning Rate\n",
        "\n",
        "<img style=\"float: left;\" src=\"https://miro.medium.com/max/2796/1*6Zr7nkI97IGT9e_tpgK-_g.png\" width=800>\n",
        "\n",
        "Die Lernrate beschreibt, wie große Schritte das Neuronale Netzwerk in jedem Trainingsabschnitt weitergeht. Ist die Lernrate klein, so lernt das Netzwerk ändert das Netzwerk in jedem Schritt nur sehr wenig. Ist die Lernrate groß, kann das Netzwerk auch größere Schritte tun, aber es wird auch häufig über das Ziel hinausschießen. Ein Kompromiss muss gefunden werden!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iT4eiGEZgcx"
      },
      "source": [
        "# wir laden das CNN neu; sonst \"erinnert\" es sich an den letzen Trainingsversuch!\n",
        "learner = cnn_learner(data, resnet18, metrics=error_rate, pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmU3Am1sZgc0"
      },
      "source": [
        "`fast.ai` ermöglicht es, die ideale Lernrate automatisch zu bestimmen!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEzL5IaFZgc1"
      },
      "source": [
        "suggested_lr = learner.lr_find().lr_min\n",
        "print(f'Die empfohlene Lernrate ist: {suggested_lr:.5f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29hdgNrFZgc4"
      },
      "source": [
        "learner.fit(6, lr=suggested_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUlc5NngZgc7"
      },
      "source": [
        "learner.recorder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBD1aULxZgc-"
      },
      "source": [
        "# Verbesserung 2: - Datenerweiterung // Data Augmentation\n",
        "Neuronale Netzwerke funktionieren am besten, wenn sie viele Daten haben - je mehr, desto besser! Unser Datensatz ist allerdings ziemlich klein, verglichen mit anderen Deep Learning Datensätzen (ca 10 000 Bilder mit ca  1 000 Bildern pro Klasse). Idealerweise würden wir unseren Datensatz einfach vergrößern, indem wir mehr Bilder mit hinzunehmen. Das ist meist allerdings mit sehr viel Mehraufwand und Kosten verbunden.\n",
        "\n",
        "Hier kommt die Datenerweiterung ins Spiel: anstatt viele neue Bilder zusammenzusuchen, können wir die Bilder, die wir schon haben einfach aufblähen. Ein Bild von einem Hund, das vertikalgespiegelt wurde, stellt immer noch (fast) den gleichen Hund dar - für das Neuronale Netzwerk jedoch sehen beide Bilder extrem verschieden aus!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fybnrvggZgc_"
      },
      "source": [
        "image = data.train_ds[5][0]\n",
        "_, ax = subplots(1, 2)\n",
        "show_image(image, ctx=ax[0], title='original')\n",
        "show_image(image.flip_lr(), ctx=ax[1], title='gespiegelt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8Oyu1owZgdC"
      },
      "source": [
        "Was können wir noch machen, außer das Bild zu spiegeln?\n",
        "* kleine oder große Rotationen\n",
        "* Zentrum des Bildes innerhalb des Bildes verschieben und reinzoomen\n",
        "* Belichtung und Kontrast\n",
        "* Perspektivveränderungen\n",
        "* ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s45N16WBZgdC"
      },
      "source": [
        "image = data.train_ds[5][0]\n",
        "_, ax = subplots(1, 3)\n",
        "rrc = RandomResizedCrop(128, min_scale=0.35)\n",
        "show_image(image, ctx=ax[0], title='original')\n",
        "show_image(rrc(image), ctx=ax[1], title='zufälliger Zoom 1')\n",
        "show_image(rrc(image), ctx=ax[2], title='zufälliger Zoom 2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXCUSvC3ZgdF"
      },
      "source": [
        "Und wie binden wir das jetzt ins Training ein?\n",
        "In `fast.ai` werden Data Augmentations (häufig \"transforms\" oder kurz \"tfms\" genannt) über `item_tfms` und `batch_tfms` and den Datensatz übergeben. Der Unterschied zwischen `item_tfms` und `batch_tfms` ist für uns nicht wichtig - jede Bildtransformation gehört entweder ins eine oder ins andere.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nytnI3_5ZgdF"
      },
      "source": [
        "size = 128\n",
        "item_tfms = [\n",
        "    # zufälliger Zoom\n",
        "    RandomResizedCrop(size, min_scale=0.35),\n",
        "    # zufällige vertikale Spiegelung\n",
        "    FlipItem(0.5),\n",
        "]\n",
        "batch_tfms = [\n",
        "    # zufällige Rotation um maximal 10°; in 50% der Bilder\n",
        "    Rotate(max_deg=10, p=0.5),\n",
        "    # zufällige Helligkeitsveränderung um maximal 10%; in 50% der Bilder\n",
        "    Brightness(max_lighting=0.1, p=0.5)\n",
        "]\n",
        "data = ImageDataLoaders.from_folder(\n",
        "    'data/imagewoof2-160/',\n",
        "    train='train',\n",
        "    valid='val',\n",
        "    item_tfms=item_tfms,\n",
        "    batch_tfms=batch_tfms,\n",
        ")\n",
        "data.show_batch()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqTzJ6NaZgdI"
      },
      "source": [
        "learner = cnn_learner(data, resnet18, metrics=error_rate, pretrained=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac2dQvjVZgdL"
      },
      "source": [
        "suggested_lr = learner.lr_find().lr_min\n",
        "print(f'Die empfohlene Lernrate ist: {suggested_lr:.5f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58GXAVtxZgdO"
      },
      "source": [
        "learner.fit(6, lr=suggested_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK9IGV2nZgdQ"
      },
      "source": [
        "learner.recorder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXO9zByLZgdU"
      },
      "source": [
        "**Immer noch weit weg von unserem Ziel!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UW03QuOMgZc"
      },
      "source": [
        "# Andere Ideen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWsgOBx5ZgdU"
      },
      "source": [
        "**Möglichkeit 1: länger trainieren!**\n",
        "    Und das funktioniert meist auch ganz gut, zu einem gewissen Grad. In unserem Beispiel etwa habe ich genau den gleichen Code mit 64 Epochen (ca 10-15 Minuten auf lokalem Server statt Google Colab) durchlaufen lassen und die Fehlerrate fällt auf etwa **27%**, eine deutliche Verbesserung. Die Datenerweiterung entfaltet ihre volle Kraft auch erst bei deutlich mehr als 10 Trainingsepochen. Aber dafür haben wir doch jetzt keine Zeit!\n",
        "    \n",
        "**Möglichkeit 2: kompliziertere Trainingsalgorithmen.**\n",
        "    Funktioniert manchmal besser, manchmal nicht\n",
        "\n",
        "**Möglichkeit 3: andere Netzwerkarchitektur.**\n",
        "    In unserem Beispiel haben wir ein `ResNet18` verwendet, ein Standardnetzwerk mit ca 18 Layern. Wir könnten ein tieferes oder weniger tiefes Netzwerk verwenden (zB `ResNet50` mit 50 Layern), oder eine andere Art von Architektur. Da wir allerdings nur relativ wenige Datenpunkte haben, werden wir nicht viel von tieferen Architekturen profitieren, und in vielen Anwendungen sind `ResNets` der state-of-the-art, oder zumindest nah daran.\n",
        "    \n",
        "    \n",
        "oder:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LExX4H6ZgdV"
      },
      "source": [
        "# Verbesserung 3: Transferlernen // Transfer Learning\n",
        "Die Idee beim Transferlernen ist, dass Neuronale Netze aus Erfahrung lernen können. Wir können unser Netzwerk zuerst auf einem riesigen und allgemeinen Datensatz \"vortrainieren\" und dann das gleiche Netzwerk auf unserem kleinen, speziellen Datensatz wiederverwenden. Das tolle daran: wir müssen das Netzwerk nur ein einziges mal vortrainieren um es dann immer und immer wieder auf verschiedene Anwendungsfälle anwenden zu können. Und da das nur einmal gemacht werden muss, haben das andere Leute für uns bereits getan und wir müssen `fast.ai` einfach nur sagen, dass wir ein vortrainiertes Netzwerk haben wollen!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtsO4Mi0ZgdV"
      },
      "source": [
        "Der einzige Unterschied beim Laden des Netzwerkes ist das `pretrained=True` Argument!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8U3X-jKZgdW"
      },
      "source": [
        "learner = cnn_learner(data, resnet18, metrics=error_rate, pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUT2n8BcZgdY"
      },
      "source": [
        "Beim trainieren könnten wir wieder die gleiche Funktion wie zuvor nehmen `learner.fit(12, lr=suggested_lr)`. Dies ist aber nicht optimal - um das meiste aus dem vortrainierten Netzwerk zu holen, verwenden wir die Funktion: `learner.fine_tune(freeze_epochs=4, epochs=8)`. Wir lassen an dieser Stelle auch die Lernrate aus - sie kann festgelegt werden, aber der Einfachheit halber überlassen wir das hier der `fast.ai` Bibliothek."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddqsDybSZgdZ"
      },
      "source": [
        "learner.fine_tune(freeze_epochs=1, epochs=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzNrFUtnZgdb"
      },
      "source": [
        "**Et voilà!**\n",
        "\n",
        "Wir schaffen es fast zu 10% Fehlerrate, während \"zufälliges Raten\" eine Fehlerrate von ~90% hätte! Die Unterscheidung verschiedener Hunderassen ist ein anspruchsvolles Problem, aber wir haben es geschafft, innerhalb von 45 Minuten ein durchaus akzeptables Vorhersagemodell zu trainieren!"
      ]
    }
  ]
}